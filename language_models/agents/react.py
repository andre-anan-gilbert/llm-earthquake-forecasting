"""ReAct agent."""

from __future__ import annotations

import json
import logging
from enum import Enum
from typing import Any, Generator, Type

import tiktoken
from pydantic import BaseModel, ValidationError

from language_models.models.llm import ChatMessage, ChatMessageRole, OpenAILanguageModel
from language_models.tools.tool import Tool

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(message)s",
    datefmt="%d/%m/%y %H:%M:%S",
)

_MODEL_TOKEN_LIMIT = {
    "gpt-4": 8192,
    "gpt-4-32k": 32768,
    "gpt-35-turbo": 4096,
    "gpt-35-turbo-16k": 16385,
}

_FORMAT_INSTRUCTIONS = """Respond to the user as helpfully and accurately as possible.

You have access to the following tools: {tools}

Please ALWAYS use the following JSON format:
{{
  "thought": "You should always think about what to do consider previous and subsequent steps",
  "tool": "The tool to use. Must be on of {tool_names}",
  "tool_input": "Valid keyword arguments",
}}

Observation: tool result
... (this Thought/Tool/Tool Input/Observation can repeat N times)

When you know the answer, you MUST use the following JSON format:
{{
  "thought": "I now know what to respond",
  "tool": "Final Answer",
  "tool_input": "Valid keyword arguments",
}}"""


def num_tokens_from_messages(messages: list[ChatMessage]) -> int:
    """Counts the number of tokens in the conversation history."""
    encoding = tiktoken.get_encoding("cl100k_base")
    num_tokens = 0
    for message in messages:
        num_tokens += 4
        for key, value in message.model_dump().items():
            num_tokens += len(encoding.encode(value))
            if key == "name":
                num_tokens += -1
    num_tokens += 2
    return num_tokens


class LLMCoTStep(str, Enum):
    THOUGHT = "thought"
    TOOL = "tool"
    FINAL_ANSWER = "final_answer"


class LLMCoTTool(BaseModel):
    name: str
    args: dict[str, Any]
    response: Any


class LLMCoT(BaseModel):
    step: LLMCoTStep
    content: str | LLMCoTTool | dict[str, Any]

    class Config:
        use_enum_values = True


class LLMResponse(BaseModel):
    thought: str
    tool: str
    tool_input: dict[str, Any]


class AgentResponse(BaseModel):
    prompt: str
    final_answer: dict[str, Any]
    chain_of_thought: list[dict[str, Any]]
    last_tool: dict[str, Any] | None


class ReActAgent(BaseModel):
    """Class that implements a ReAct agent."""

    llm: OpenAILanguageModel
    tools: dict[str, Tool] | None
    task_prompt: str
    task_prompt_variables: list[str]
    output_format: Type[BaseModel]
    chat_messages: list[ChatMessage]
    iterations: int = 20

    def reset(self) -> None:
        """Resets the ReAct agent."""
        self.chat_messages = [self.chat_messages[0]]

    def _trim_conversation(self) -> None:
        """Trims the chat messages to fit the LLM context length."""
        num_tokens = num_tokens_from_messages(self.chat_messages)
        while num_tokens + self.llm.max_tokens >= _MODEL_TOKEN_LIMIT[self.llm.model]:
            del self.chat_messages[1]
            num_tokens = num_tokens_from_messages(self.chat_messages)

    def _parse_response(self, response: str) -> tuple[LLMResponse | None, str]:
        """Parses the LLM response."""
        try:
            response = json.loads(response, strict=False)
            response = LLMResponse.model_validate(response)
            observation = None
        except json.decoder.JSONDecodeError:
            response = None
            observation = (
                "Your response format was incorrect."
                + "\n\nPlease ALWAYS use the following JSON format:"
                + '\n{\n\t"thought": "You should always think about what to do consider previous and subsequent steps",'
                + f'\n\t"tool": "The tool to use. Must be one of {list(self.tools.keys())}",'
                + '\n\t"tool_input": "Valid keyword arguments"\n}'
                + "\n\nObservation: tool result"
                + "\n... (this Thought/Tool/Tool Input/Observation can repeat N times)"
                + "\n\nWhen you know the answer, you MUST use the following JSON format:"
                + '\n{\n\t"thought": "You should always think about what to do consider previous and subsequent steps",'
                + '\n\t"tool": "Final Answer",'
                + '\n\t"tool_input": "Valid keyword arguments"\n}'
            )
        except ValidationError as e:
            response = None
            observation = f"Your response failed validation. The error was: {e}"
        return response, observation

    def invoke(self, prompt: dict[str, Any]) -> Generator:
        """Runs the AI agent."""
        previous_work = []
        chain_of_thought: list[LLMCoT] = []
        prompt = self.task_prompt.format(
            **{
                variable: prompt.get(variable)
                for variable in self.task_prompt_variables
            }
        )
        logging.info("Prompt:\n%s", prompt)
        self.chat_messages.append(
            ChatMessage(role=ChatMessageRole.USER, content=prompt)
        )
        last_tool = None
        iterations = 0
        while iterations <= self.iterations:
            self._trim_conversation()
            print(self.chat_messages[-1].content)
            response = self.llm.get_completion(self.chat_messages)
            logging.info("Raw response:\n%s", response)
            response, observation = self._parse_response(response)
            if response is not None:
                logging.info("Thought:\n%s", response.thought)
                previous_work.append(f"Thought: {response.thought}")
                chain_of_thought.append(
                    LLMCoT(step=LLMCoTStep.THOUGHT, content=response.thought)
                )
                yield {"step": "thought", "content": response.thought}
                if response.tool == "Final Answer":
                    try:
                        logging.info("Final answer:\n%s", response.tool_input)
                        result = self.output_format.model_validate(response.tool_input)
                        final_answer = result.model_dump()
                        chain_of_thought.append(
                            LLMCoT(step=LLMCoTStep.FINAL_ANSWER, content=final_answer)
                        )
                        yield {
                            "step": "final_answer",
                            "content": AgentResponse(
                                prompt=prompt,
                                final_answer=final_answer,
                                chain_of_thought=[
                                    step.model_dump() for step in chain_of_thought
                                ],
                                last_tool=last_tool,
                            ),
                        }
                        return
                    except ValidationError as e:
                        observation = (
                            f"Your final answer failed validation. The error was: {e}"
                        )
                else:
                    if self.tools is not None:
                        logging.info("Tool:\n%s", response.tool)
                        logging.info("Tool input:\n%s", response.tool_input)
                        tool = self.tools.get(response.tool)
                        if tool is not None:
                            tool_response = tool.invoke(response.tool_input)
                            observation = f"Tool response:\n{tool_response}"
                            logging.info(observation)
                            previous_work.append(f"Tool: {tool.name}")
                            previous_work.append(f"Tool Input: {response.tool_input}")
                            chain_of_thought.append(
                                LLMCoT(
                                    step=LLMCoTStep.TOOL,
                                    content=LLMCoTTool(
                                        name=response.tool,
                                        args=response.tool_input,
                                        response=tool_response,
                                    ),
                                )
                            )
                            last_tool = {"name": tool.name, "args": response.tool_input}
                            yield {"step": "tool", "content": tool.name}
                        else:
                            observation = (
                                f"{response.tool} tool doesn't exist."
                                f" Try one of these tools: {list(self.tools.keys())}"
                            )
            previous_work.append(f"Observation: {observation}")
            self.chat_messages[-1].content = (
                prompt
                + "\n\nThis was your previous work:\n\n"
                + "\n".join(previous_work)
            )
            iterations += 1

        yield {
            "step": "final_answer",
            "content": AgentResponse(
                prompt=prompt,
                final_answer={
                    key: None
                    for key in self.output_format.model_json_schema()["properties"]
                },
                chain_of_thought=[step.model_dump() for step in chain_of_thought],
                last_tool=last_tool,
            ),
        }
        return

    @classmethod
    def create(
        cls,
        llm: OpenAILanguageModel,
        system_prompt: str,
        task_prompt: str,
        task_prompt_variables: list[str],
        output_format: Type[BaseModel],
        tools: list[Tool] | None = None,
        iterations: int = 20,
    ) -> ReActAgent:
        """Creates a instance of the ReAct agent."""
        output_tool = Tool(
            func=lambda _: None,
            name="Final Answer",
            description="Provides the final answer.",
            args_schema=output_format,
        )
        tools = [output_tool] if tools is None else tools + [output_tool]
        format_instructions = _FORMAT_INSTRUCTIONS.format(
            tools=[str(tool) for tool in tools],
            tool_names=[tool.name for tool in tools],
        )
        chat_messages = [
            ChatMessage(
                role=ChatMessageRole.SYSTEM,
                content="\n\n".join([system_prompt, format_instructions]),
            )
        ]
        return ReActAgent(
            llm=llm,
            tools={tool.name: tool for tool in tools},
            task_prompt=task_prompt,
            task_prompt_variables=task_prompt_variables,
            output_format=output_format,
            chat_messages=chat_messages,
            iterations=iterations,
        )
